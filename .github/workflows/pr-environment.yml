# =============================================================================
# PR Environment Workflow
# Creates/destroys ephemeral environments for pull requests
# Cloud-agnostic: Works with AWS/Azure/GCP
# Database-per-PR pattern with shared managed infrastructure
# =============================================================================

name: PR Environment

on:
  pull_request:
    types: [opened, synchronize, reopened, closed]
    branches: [develop, main]
  workflow_dispatch:
    inputs:
      pr_number:
        description: 'PR number to deploy'
        required: true
        type: number

concurrency:
  group: pr-${{ github.event.pull_request.number || github.event.inputs.pr_number }}
  cancel-in-progress: false

env:
  PR_NUMBER: ${{ github.event.pull_request.number || github.event.inputs.pr_number }}
  NAMESPACE: pr-${{ github.event.pull_request.number || github.event.inputs.pr_number }}
  CLOUD_PROVIDER: ${{ vars.CLOUD_PROVIDER || 'aws' }}

permissions:
  contents: read
  packages: write
  pull-requests: write

jobs:
  # ===========================================================================
  # Create/Update PR Environment
  # ===========================================================================
  deploy:
    if: github.event_name == 'workflow_dispatch' || github.event.action != 'closed'
    runs-on: ubuntu-latest
    environment: development

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install uv
        uses: astral-sh/setup-uv@v3

      # --- Cloud Authentication (based on CLOUD_PROVIDER) ---
      - name: Configure AWS credentials
        if: ${{ env.CLOUD_PROVIDER == 'aws' }}
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ vars.AWS_REGION || 'us-west-1' }}

      - name: Configure kubectl for AWS
        if: ${{ env.CLOUD_PROVIDER == 'aws' }}
        run: aws eks update-kubeconfig --name elevaite-dev --region ${{ vars.AWS_REGION || 'us-west-1' }}

      - name: Configure Azure credentials
        if: ${{ env.CLOUD_PROVIDER == 'azure' }}
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Configure kubectl for Azure
        if: ${{ env.CLOUD_PROVIDER == 'azure' }}
        run: az aks get-credentials --resource-group elevaite-dev --name elevaite-dev

      - name: Configure GCP credentials
        if: ${{ env.CLOUD_PROVIDER == 'gcp' }}
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_CREDENTIALS }}

      - name: Configure kubectl for GCP
        if: ${{ env.CLOUD_PROVIDER == 'gcp' }}
        uses: google-github-actions/get-gke-credentials@v2
        with:
          cluster_name: elevaite-dev
          location: ${{ vars.GCP_REGION || 'us-central1' }}

      - name: Verify kubectl configuration
        run: |
          echo "Checking kubectl configuration..."
          kubectl config current-context || echo "No kubectl context configured"
          kubectl cluster-info || echo "Cannot connect to cluster"
          kubectl version --client

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.0
          terraform_wrapper: false

      - name: Get Terraform outputs
        id: terraform
        run: |
          cd terraform/environments/dev/${{ env.CLOUD_PROVIDER }}
          terraform init
          DB_HOST_RAW=$(terraform output -raw database_host)
          # Strip port if present in hostname
          DB_HOST_CLEAN=$(echo "$DB_HOST_RAW" | cut -d: -f1)
          echo "db_host=$DB_HOST_CLEAN" >> $GITHUB_OUTPUT
          echo "rabbitmq_host=$(terraform output -raw rabbitmq_host)" >> $GITHUB_OUTPUT
          echo "storage_bucket=$(terraform output -raw storage_bucket)" >> $GITHUB_OUTPUT

      - name: Create PR Database
        if: steps.terraform.outputs.db_host != ''
        env:
          DB_HOST: ${{ steps.terraform.outputs.db_host }}
          DB_PASSWORD: ${{ secrets.DEV_DB_PASSWORD }}
          DB_USER: elevaite
          DB_ADMIN_DATABASE: elevaite_dev
        run: |
          # Install psql
          sudo apt-get update && sudo apt-get install -y postgresql-client

          # Create database for this PR (DB_HOST already cleaned by Terraform step)
          PGPASSWORD="$DB_PASSWORD" psql \
            -h "$DB_HOST" \
            -p 5432 \
            -U "$DB_USER" \
            -d "$DB_ADMIN_DATABASE" \
            -c "CREATE DATABASE pr_${{ env.PR_NUMBER }};" || echo "Database may already exist"

          # Create auth_default schema for auth-api (multi-tenant)
          PGPASSWORD="$DB_PASSWORD" psql \
            -h "$DB_HOST" \
            -p 5432 \
            -U "$DB_USER" \
            -d "pr_${{ env.PR_NUMBER }}" \
            -c "CREATE SCHEMA IF NOT EXISTS auth_default;"

          # Run migrations for workflow-engine
          export DATABASE_URL="postgresql://${DB_USER}:${DB_PASSWORD}@${DB_HOST}:5432/pr_${{ env.PR_NUMBER }}?sslmode=require"
          export SQLALCHEMY_DATABASE_URL="postgresql+asyncpg://${DB_USER}:${DB_PASSWORD}@${DB_HOST}:5432/pr_${{ env.PR_NUMBER }}?ssl=require"
          export ALEMBIC_SQLALCHEMY_URL="postgresql://${DB_USER}:${DB_PASSWORD}@${DB_HOST}:5432/pr_${{ env.PR_NUMBER }}?sslmode=require"

          cd python_apps/workflow-engine-poc
          uv sync
          uv run alembic upgrade head

          # Run migrations for auth-api (schema-per-tenant)
          cd ../auth_api
          uv sync
          ALEMBIC_SCHEMA=auth_default uv run alembic upgrade head

      - name: Free up disk space
        run: |
          # Remove unnecessary files to free up space for Docker builds
          sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc
          sudo docker system prune -af --volumes
          df -h

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build and push Auth API
        uses: docker/build-push-action@v5
        with:
          context: .
          file: python_apps/auth_api/Dockerfile
          push: true
          tags: ghcr.io/${{ github.repository }}/elevaite-auth-api:pr-${{ env.PR_NUMBER }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Build and push Workflow Engine
        uses: docker/build-push-action@v5
        with:
          context: .
          file: python_apps/workflow-engine-poc/Dockerfile
          push: true
          tags: ghcr.io/${{ github.repository }}/elevaite-workflow-engine:pr-${{ env.PR_NUMBER }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      # TODO: Re-enable ingestion service when ready
      # - name: Build and push Ingestion Service
      #   uses: docker/build-push-action@v5
      #   with:
      #     context: .
      #     file: python_apps/ingestion-service/Dockerfile
      #     push: true
      #     tags: ghcr.io/${{ github.repository }}/elevaite-ingestion:pr-${{ env.PR_NUMBER }}
      #     cache-from: type=gha
      #     cache-to: type=gha,mode=max

      - name: Create Kubernetes namespace
        run: |
          kubectl create namespace ${{ env.NAMESPACE }} --dry-run=client -o yaml | kubectl apply -f -

      - name: Create Kubernetes secrets
        run: |
          # Create Docker registry secret for pulling images from GHCR
          kubectl create secret docker-registry ghcr-pull-secret \
            --namespace ${{ env.NAMESPACE }} \
            --docker-server=ghcr.io \
            --docker-username=${{ github.actor }} \
            --docker-password=${{ secrets.GHCR_PAT }} \
            --dry-run=client -o yaml | kubectl apply -f -

          kubectl create secret generic elevaite-db-credentials \
            --namespace ${{ env.NAMESPACE }} \
            --from-literal=POSTGRES_USER=elevaite \
            --from-literal=POSTGRES_PASSWORD=${{ secrets.DEV_DB_PASSWORD }} \
            --dry-run=client -o yaml | kubectl apply -f -

          # Internal RabbitMQ uses hardcoded credentials (elevaite/elevaite)
          kubectl create secret generic elevaite-rabbitmq-credentials \
            --namespace ${{ env.NAMESPACE }} \
            --from-literal=RABBITMQ_USER=elevaite \
            --from-literal=RABBITMQ_PASSWORD=elevaite \
            --dry-run=client -o yaml | kubectl apply -f -

          kubectl create secret generic elevaite-storage-credentials \
            --namespace ${{ env.NAMESPACE }} \
            --from-literal=AWS_ACCESS_KEY_ID=${{ secrets.DEV_STORAGE_ACCESS_KEY }} \
            --from-literal=AWS_SECRET_ACCESS_KEY=${{ secrets.DEV_STORAGE_SECRET_KEY }} \
            --dry-run=client -o yaml | kubectl apply -f -

          # Qdrant credentials (optional - for vector database)
          if [ -n "${{ secrets.DEV_QDRANT_API_KEY }}" ]; then
            kubectl create secret generic elevaite-qdrant-credentials \
              --namespace ${{ env.NAMESPACE }} \
              --from-literal=QDRANT_API_KEY=${{ secrets.DEV_QDRANT_API_KEY }} \
              --dry-run=client -o yaml | kubectl apply -f -
          fi

          # Application secrets (API keys, JWT, database, etc.)
          kubectl create secret generic elevaite-secrets \
            --namespace ${{ env.NAMESPACE }} \
            --from-literal=JWT_SECRET=${{ secrets.JWT_SECRET }} \
            --from-literal=OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }} \
            --from-literal=db_host=${{ steps.terraform.outputs.db_host }} \
            --from-literal=db_port=5432 \
            --from-literal=db_user=elevaite \
            --from-literal=db_password=${{ secrets.DEV_DB_PASSWORD }} \
            --from-literal=db_name=pr_${{ env.PR_NUMBER }} \
            --from-literal=POSTGRES_USER=elevaite \
            --from-literal=POSTGRES_PASSWORD=${{ secrets.DEV_DB_PASSWORD }} \
            --from-literal=DATABASE_URL=postgresql+asyncpg://elevaite:${{ secrets.DEV_DB_PASSWORD }}@${{ steps.terraform.outputs.db_host }}:5432/pr_${{ env.PR_NUMBER }}?ssl=require \
            --from-literal=SQLALCHEMY_DATABASE_URL=postgresql+asyncpg://elevaite:${{ secrets.DEV_DB_PASSWORD }}@${{ steps.terraform.outputs.db_host }}:5432/pr_${{ env.PR_NUMBER }}?ssl=require \
            --from-literal=ALEMBIC_SQLALCHEMY_URL=postgresql://elevaite:${{ secrets.DEV_DB_PASSWORD }}@${{ steps.terraform.outputs.db_host }}:5432/pr_${{ env.PR_NUMBER }}?sslmode=require \
            --from-literal=RABBITMQ_USER=elevaite \
            --from-literal=RABBITMQ_PASSWORD=elevaite \
            --from-literal=RABBITMQ_HOST=elevaite-pr-${{ env.PR_NUMBER }}-rabbitmq \
            --from-literal=AWS_ACCESS_KEY_ID=${{ secrets.DEV_STORAGE_ACCESS_KEY }} \
            --from-literal=AWS_SECRET_ACCESS_KEY=${{ secrets.DEV_STORAGE_SECRET_KEY }} \
            --dry-run=client -o yaml | kubectl apply -f -

      - name: Setup Helm
        uses: azure/setup-helm@v4

      - name: Get Load Balancer IP
        id: lb
        run: |
          # Get the ingress-nginx load balancer hostname or IP
          LB_HOSTNAME=$(kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "")
          LB_IP=$(kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null || echo "")

          echo "LB Hostname: $LB_HOSTNAME"
          echo "LB IP: $LB_IP"

          # If we got a hostname (AWS NLB/ELB), resolve it to IP
          if [[ -n "$LB_HOSTNAME" && -z "$LB_IP" ]]; then
            echo "Resolving hostname to IP..."
            # Try dig first, fall back to nslookup, then getent
            LB_IP=$(dig +short "$LB_HOSTNAME" | grep -E '^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$' | head -1) || \
            LB_IP=$(nslookup "$LB_HOSTNAME" 2>/dev/null | grep -A1 'Name:' | grep 'Address:' | awk '{print $2}' | head -1) || \
            LB_IP=$(getent hosts "$LB_HOSTNAME" 2>/dev/null | awk '{print $1}' | head -1) || \
            LB_IP=""
          fi

          if [[ -z "$LB_IP" ]]; then
            echo "ERROR: Could not resolve load balancer IP"
            exit 1
          fi

          # Validate IP format
          if ! [[ "$LB_IP" =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
            echo "ERROR: Invalid IP format: $LB_IP"
            exit 1
          fi

          # Convert dots to dashes for nip.io
          LB_IP_DASHED=$(echo "$LB_IP" | tr '.' '-')

          echo "lb_ip=$LB_IP" >> $GITHUB_OUTPUT
          echo "lb_ip_dashed=$LB_IP_DASHED" >> $GITHUB_OUTPUT
          echo "Resolved Load Balancer IP: $LB_IP"
          echo "nip.io hostname will be: pr-${{ env.PR_NUMBER }}.$LB_IP_DASHED.nip.io"

      - name: Deploy with Helm
        run: |
          # Use nip.io for DNS (no custom domain needed)
          NIP_HOST="pr-${{ env.PR_NUMBER }}.${{ steps.lb.outputs.lb_ip_dashed }}.nip.io"

          helm upgrade --install elevaite-pr-${{ env.PR_NUMBER }} ./helm/elevaite \
            --namespace ${{ env.NAMESPACE }} \
            --values ./helm/elevaite/values-pr.yaml \
            --set global.imageRegistry=ghcr.io/${{ github.repository }} \
            --set global.environment=pr \
            --set global.imagePullSecrets[0].name=ghcr-pull-secret \
            --set authApi.image.tag=pr-${{ env.PR_NUMBER }} \
            --set workflowEngine.image.tag=pr-${{ env.PR_NUMBER }} \
            --set ingestion.enabled=false \
            --set worker.image.tag=pr-${{ env.PR_NUMBER }} \
            --set postgresql.host=${{ steps.terraform.outputs.db_host }} \
            --set postgresql.database=pr_${{ env.PR_NUMBER }} \
            --set rabbitmq.internal.enabled=true \
            --set rabbitmq.vhost=/ \
            --set objectStorage.bucket=${{ steps.terraform.outputs.storage_bucket }} \
            --set migrations.enabled=false \
            --set frontend.auth.enabled=false \
            --set frontend.elevaite.enabled=false \
            --set ingress.enabled=true \
            --set ingress.hosts[0].host=$NIP_HOST \
            --set ingress.hosts[0].paths[0].path=/ \
            --set ingress.hosts[0].paths[0].pathType=Prefix \
            --set ingress.hosts[0].paths[0].service=workflow-engine \
            --set ingress.tls[0].secretName=elevaite-pr-${{ env.PR_NUMBER }}-tls \
            --set ingress.tls[0].hosts[0]=$NIP_HOST \
            --set "ingress.annotations.cert-manager\\.io/cluster-issuer=letsencrypt-staging" \
            --wait \
            --timeout 10m

      - name: Show deployment status
        if: always()
        run: |
          echo "=== Deployment Status ==="
          kubectl get pods -n ${{ env.NAMESPACE }} -o wide
          echo ""
          echo "=== Auth-API Logs ==="
          kubectl logs -n ${{ env.NAMESPACE }} -l app.kubernetes.io/component=auth-api --tail=50 || echo "No auth-api logs"
          echo ""
          echo "=== Recent Events ==="
          kubectl get events -n ${{ env.NAMESPACE }} --sort-by='.lastTimestamp' | tail -15

      - name: Post deployment URL
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const lbIpDashed = '${{ steps.lb.outputs.lb_ip_dashed }}';
            const prNumber = '${{ env.PR_NUMBER }}';
            const nipHost = `pr-${prNumber}.${lbIpDashed}.nip.io`;
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## ðŸš€ PR Environment Deployed\n\n**ðŸ”— URL:** https://${nipHost}\n\n**Cloud:** ${{ env.CLOUD_PROVIDER }}\n**Database:** \`pr_${prNumber}\`\n**Namespace:** \`${{ env.NAMESPACE }}\`\n\n---\n*This environment will be automatically destroyed when the PR is closed.*`
            })

  # ===========================================================================
  # Cleanup PR Environment
  # ===========================================================================
  cleanup:
    if: github.event.action == 'closed'
    runs-on: ubuntu-latest
    environment: development

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      # --- Cloud Authentication ---
      - name: Configure AWS credentials
        if: ${{ env.CLOUD_PROVIDER == 'aws' }}
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ vars.AWS_REGION || 'us-west-1' }}

      - name: Configure kubectl for AWS
        if: ${{ env.CLOUD_PROVIDER == 'aws' }}
        run: aws eks update-kubeconfig --name elevaite-dev --region ${{ vars.AWS_REGION || 'us-west-1' }}

      - name: Configure Azure credentials
        if: ${{ env.CLOUD_PROVIDER == 'azure' }}
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Configure kubectl for Azure
        if: ${{ env.CLOUD_PROVIDER == 'azure' }}
        run: az aks get-credentials --resource-group elevaite-dev --name elevaite-dev

      - name: Configure GCP credentials
        if: ${{ env.CLOUD_PROVIDER == 'gcp' }}
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_CREDENTIALS }}

      - name: Configure kubectl for GCP
        if: ${{ env.CLOUD_PROVIDER == 'gcp' }}
        uses: google-github-actions/get-gke-credentials@v2
        with:
          cluster_name: elevaite-dev
          location: ${{ vars.GCP_REGION || 'us-central1' }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.0
          terraform_wrapper: false

      - name: Get Terraform outputs
        id: terraform
        run: |
          cd terraform/environments/dev/${{ env.CLOUD_PROVIDER }}
          terraform init
          DB_HOST_RAW=$(terraform output -raw database_host)
          # Strip port if present in hostname
          DB_HOST_CLEAN=$(echo "$DB_HOST_RAW" | cut -d: -f1)
          echo "db_host=$DB_HOST_CLEAN" >> $GITHUB_OUTPUT

      - name: Setup Helm
        uses: azure/setup-helm@v4

      - name: Delete Helm release
        run: |
          helm uninstall elevaite-pr-${{ env.PR_NUMBER }} --namespace ${{ env.NAMESPACE }} || true

      - name: Delete Kubernetes namespace
        run: |
          kubectl delete namespace ${{ env.NAMESPACE }} --ignore-not-found

      - name: Drop PR Database
        env:
          DB_HOST: ${{ steps.terraform.outputs.db_host }}
          DB_PASSWORD: ${{ secrets.DEV_DB_PASSWORD }}
          DB_USER: elevaite
          DB_ADMIN_DATABASE: elevaite_dev
        run: |
          sudo apt-get update && sudo apt-get install -y postgresql-client

          # Terminate connections (DB_HOST already cleaned by Terraform step)
          PGPASSWORD="$DB_PASSWORD" psql \
            -h "$DB_HOST" \
            -p 5432 \
            -U "$DB_USER" \
            -d "$DB_ADMIN_DATABASE" \
            -c "SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = 'pr_${{ env.PR_NUMBER }}';" || true

          # Drop database
          PGPASSWORD="$DB_PASSWORD" psql \
            -h "$DB_HOST" \
            -p 5432 \
            -U "$DB_USER" \
            -d "$DB_ADMIN_DATABASE" \
            -c "DROP DATABASE IF EXISTS pr_${{ env.PR_NUMBER }};"

      - name: Post cleanup comment
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## ðŸ§¹ PR Environment Cleaned Up\n\n- âœ… Kubernetes namespace deleted\n- âœ… Database \`pr_${{ env.PR_NUMBER }}\` dropped\n- âœ… Helm release removed`
            })
