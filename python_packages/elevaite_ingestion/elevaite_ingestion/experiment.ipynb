{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Late Interaction mechanism to query-to-chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.11 ('elevaite_ingest')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n elevaite_ingest ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "context_length, dimension --done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"STAGE_1: LOADING\" --> \"STAGE_2: PARSING\" --> \"STAGE_3: CHUNKING\" --> \"STAGE_4: EMBEDDING\" -->\n",
    "        ||\n",
    "   [s3 , local]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"STAGE_5: VECTOR_DB\" --> \"STAGE_6: RETRIEVAL\" --> \"STAGE_7: GUARDRAIL\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "at embedding stage:  1) provider_name, 2) model_name ---done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading_stage, 1) file_size, 2) no of files, 3) source_type(s3,local,) ---done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Late Interaction mechanism to query-to-chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query embedding: Q\n",
    "\n",
    "Chunk metadata and content:\n",
    "   Title Embedding::::      T        -------- high level context\n",
    "   Summary Embedding::::    S        -------- core ideas ( acts as a middle layer between ...)\n",
    "   chunk Content Embedding::::    C        -------- Fine-grained details\n",
    "   Keywords Embedding::::   K        -------- crictical/importants terms\n",
    "\n",
    "Similarity scores:\n",
    "   sim(Q, T) = 0.85\n",
    "   sim(Q,S) = 0.92\n",
    "   sim(Q, C) = 0.78\n",
    "   sim(Q, K) = 0.89   (BM25: exact matches, vs  keyword embeddings:: synonym matching, contextual understanding)\n",
    "\n",
    "Aggregated score: 0.8....(weighted Sum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "even if the content embedding fails to represent some key aspects due to compression, the other embeddings act as backup mechanisms to preserve those meanings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "information loss (decreases)\n",
    "recall (increases)\n",
    "precision (increase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "problem statement:\n",
    "---> Out-of-Context problem \n",
    "\n",
    "=========> Chunk Out-of-Context problem ----(most of the RAG provider solving this problem at chunk level)\n",
    "----------------> 1) Contextual header (by anthropic)\n",
    "----------------> 2) RSE(Relevant Segment Extraction) (by dsRAG)\n",
    "\n",
    "=========> I am solving Out-of-context problem before chunking.\n",
    "----------------> 1) BY adding context at the sentence level (self-contained)---> context-aware sentenceObject\n",
    "----------------------------> it actuallysolves the incompleteness issue in chunk\n",
    "----------------------------> Also, it gives the context to chunk\n",
    "----------------------------------------> Basically, Creating the Self-contained Chunk(completeness + context)\n",
    "((now, semntic chunking will be more accurate. ****Imp))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explainabilty:\n",
    "1) print similarity scores (while semantic chunking)\n",
    "2) chunk boundaries with similarity drops \n",
    "\n",
    "1) print sentence object\n",
    "2) print context-aware sentence object\n",
    "3) print chunk\n",
    "4) Manual check\n",
    "5) Pass 1), 2), 3) along with original pdf page to LLM for 1) validation and 2) Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ground thruth for retrieval system: \n",
    "Finetune Colpali on TCD --> retrieve pages | + SentenceObject(Retrieved pages) ---> LLM ---> actual sentenceOBject(TCD)\n",
    "\n",
    "performance of retieval system = ROUGE[retrieved chunks/ actual sentenceOBject(TCD)]         [ for the same TCD query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns = [\n",
    "    \"Sentence Object\",\n",
    "    \"Context Aware Sentence Object\",\n",
    "    \"Query\",\n",
    "    \"Chunk Id\",\n",
    "    \"Context Aware Sequential Semantic Chunk\",\n",
    "    \"Context Aware Adaptive Chunk\",\n",
    "    \"Context Aware Hybrid Chunk\",\n",
    "    \"Context Aware Global Semantic Chunk\",\n",
    "    \"Standard Semantic Chunker(Langchain)\"\n",
    "]\n",
    "\n",
    "rows = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "df_comparison = pd.DataFrame(columns=columns, index=rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence Object</th>\n",
       "      <th>Context Aware Sentence Object</th>\n",
       "      <th>Query</th>\n",
       "      <th>Chunk Id</th>\n",
       "      <th>Context Aware Sequential Semantic Chunk</th>\n",
       "      <th>Context Aware Adaptive Chunk</th>\n",
       "      <th>Context Aware Hybrid Chunk</th>\n",
       "      <th>Context Aware Global Semantic Chunk</th>\n",
       "      <th>Standard Semantic Chunker(Langchain)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentence Object Context Aware Sentence Object Query Chunk Id  \\\n",
       "1              NaN                           NaN   NaN      NaN   \n",
       "2              NaN                           NaN   NaN      NaN   \n",
       "3              NaN                           NaN   NaN      NaN   \n",
       "4              NaN                           NaN   NaN      NaN   \n",
       "5              NaN                           NaN   NaN      NaN   \n",
       "6              NaN                           NaN   NaN      NaN   \n",
       "7              NaN                           NaN   NaN      NaN   \n",
       "8              NaN                           NaN   NaN      NaN   \n",
       "9              NaN                           NaN   NaN      NaN   \n",
       "10             NaN                           NaN   NaN      NaN   \n",
       "\n",
       "   Context Aware Sequential Semantic Chunk Context Aware Adaptive Chunk  \\\n",
       "1                                      NaN                          NaN   \n",
       "2                                      NaN                          NaN   \n",
       "3                                      NaN                          NaN   \n",
       "4                                      NaN                          NaN   \n",
       "5                                      NaN                          NaN   \n",
       "6                                      NaN                          NaN   \n",
       "7                                      NaN                          NaN   \n",
       "8                                      NaN                          NaN   \n",
       "9                                      NaN                          NaN   \n",
       "10                                     NaN                          NaN   \n",
       "\n",
       "   Context Aware Hybrid Chunk Context Aware Global Semantic Chunk  \\\n",
       "1                         NaN                                 NaN   \n",
       "2                         NaN                                 NaN   \n",
       "3                         NaN                                 NaN   \n",
       "4                         NaN                                 NaN   \n",
       "5                         NaN                                 NaN   \n",
       "6                         NaN                                 NaN   \n",
       "7                         NaN                                 NaN   \n",
       "8                         NaN                                 NaN   \n",
       "9                         NaN                                 NaN   \n",
       "10                        NaN                                 NaN   \n",
       "\n",
       "   Standard Semantic Chunker(Langchain)  \n",
       "1                                   NaN  \n",
       "2                                   NaN  \n",
       "3                                   NaN  \n",
       "4                                   NaN  \n",
       "5                                   NaN  \n",
       "6                                   NaN  \n",
       "7                                   NaN  \n",
       "8                                   NaN  \n",
       "9                                   NaN  \n",
       "10                                  NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "knowledgbase card -- update with basic details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/athrael-soju/Qdrant-Neo4j-Ollama-Graph-Rag/blob/main/processors/openai_processor.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"‭38‬\\n‭About Arlo (Process / Features / Compliance / Policy)‬\\n‭EXTERNAL KB‬\\n‭What do I need to know about the Arlo Theft Replacement‬‭program?‬\\n‭What do I need to know about the‬\\n‭Arlo Theft Replacement program?‬\\n‭This article applies to:‬\\n‭AVD4001‬ ‭AVD3001‬ ‭AVD2001‬ ‭AVD1001‬ ‭AAD1001‬ ‭AL1101‬ ‭VMC5040‬ ‭VMC4030P‬ ‭VMC4040P‬\\n‭FB1001‬ ‭VMC4041P‬ ‭VMC4050P‬ ‭VMC4060P‬ ‭VMC4030‬ ‭VMC2020‬ ‭VMC2030‬ ‭VMC2032‬\\n‭VMC3050‬ ‭VMC2050‬ ‭VMC3052‬ ‭VMC2052‬ ‭VMC3030‬\\n‭1.‬ ‭What is the Arlo Theft Replacement program?‬\\n‭The Arlo Theft Replacement (ATR) program allows the‬‭original purchasers‬‭of‬\\n‭certain Arlo devices connected to paid Arlo subscription plans to qualify for‬\\n‭replacements in the event that they are stolen.‬\\n‭2.‬ ‭What is an eligible Arlo device?‬\\n‭An “Eligible Device” is an Arlo wire-free camera product (Arlo Wire-Free, Arlo‬\\n‭Essential Outdoor Camera [2‬‭nd‬‭Generation], Arlo Essential‬‭XL Outdoor Camera‬\\n‭[2‬‭nd‬‭Generation], Arlo Essential wire-free, Arlo Pro,‬‭Arlo Pro 2, Arlo Pro 3, Arlo‬\\n‭Pro 3 Floodlight, Arlo Pro 4, Arlo Pro 5S, Arlo Ultra, and Arlo Ultra 2), Arlo‬\\n‭doorbell product (Arlo Video Doorbell [2‬‭nd‬‭Generation],‬‭Arlo Essential Video‬\\n‭Doorbell Wired, Arlo Essential Video Doorbell Wire-Free, and Arlo Audio‬\\n‭Doorbell), or Arlo wire-free light product‬‭(Arlo Security‬‭Light), and the product’s‬\\n‭accompanying batteries (if applicable). The Eligible Device must have been‬\\n‭purchased directly from an Arlo authorized reseller‬‭within the 12 months‬\\n‭preceding the theft and may have been bought as brand new or certified‬\\n‭refurbished. The Eligible Device must be registered under an Arlo account by the‬\\n‭original purchaser at the time of the theft and will be rendered inoperative when‬\\n‭registered as stolen under the ATR program.‬\\n‭3.‬ ‭What must I do to request a replacement device under the ATR program?‬\\n‭A.‬ ‭File a police report and request a copy of the report showing a case‬\\n‭number and law enforcement contact within two weeks of the theft. The‬\\n‭registered owner of the Arlo account using the Eligible Device must be the‬\\n‭person who files the police report.‬\\n‭B.‬ ‭Do NOT remove the stolen Eligible Device from your Arlo account until‬\\n‭you have contacted Arlo Support.‬\\n‭C.‬ ‭Initiate an ATR claim by contacting‬‭Arlo Support‬‭within‬‭30 days of the date‬\\n‭printed on the police report. You will need to provide Arlo with your Eligible‬\\n‭Device and account information, so that Arlo may validate and process‬\\n‭your claim. You must have valid proof of purchase of the Eligible Device to‬\\n‭initiate an ATR claim. Your recordings and personal information are‬\\n‭protected in the Arlo cloud, as long as your account credentials were not‬\\n‭stolen.‬\\n‭D.‬ ‭Once we verify the police report and your ownership of the stolen Eligible‬\\n‭Device and account, we will process the replacement. The replacement‬\\n‭will be the same or similar make and model as the original Eligible Device‬\\n‭and may be new or refurbished.‬\\n‭E.‬ ‭You must be on a paid Arlo subscription plan (Arlo Secure, Arlo Secure‬\\n‭Plus, Arlo Safe & Secure Pro for Home; Advanced, Professional, or‬\\n‭Enterprise for Business) at the time of the Eligible Device theft.‬\\n‭F.‬ ‭The theft must have occurred within the United States, Australia, or New‬\\n‭Zealand, and the law enforcement contact on the police report must be in‬\\n‭the United States, Australia, or New Zealand.‬\\n‭4.‬ ‭What is not covered under the ATR program?‬\\n‭A.‬ ‭Arlo products purchased from unauthorized resellers including third party‬\\n‭sellers on Amazon, eBay, and other marketplaces are not eligible for the‬\\n‭ATR program.‬\\n‭B.‬ ‭Arlo Go, Arlo Go 2, Arlo SmartHubs, Arlo Base Stations, Arlo Bridges, and‬\\n‭indoor cameras such as Arlo Q, Arlo Q Plus, Arlo Baby, Arlo Essential‬\\n‭Indoor Camera, and Arlo Essential Indoor Camera (2‬‭nd‬‭Generation) are‬\\n‭not eligible for the ATR program.‬\\n‭C.‬ ‭Arlo accessories such as mounts, skins, cables, solar panels, or power‬\\n‭adapters are not eligible for the ATR program.‬\\n‭D.‬ ‭The ATR program does not apply to theft during or upon delivery of your‬\\n‭Arlo Eligible Device, or to theft any time prior to the registering of the‬\\n‭Eligible Device to your Arlo account.‬\\n‭E.‬ ‭The ATR program is not transferable.‬\\n‭Arlo Small Print‬‭: The ATR program is a courtesy service‬‭provided by Arlo. Arlo will determine in‬\\n‭its sole reasonable discretion whether a claim under the ATR program meets the eligibility‬\\n‭criteria.\",\n",
    "        \"page_range\": [\n",
    "            1,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.11 ('elevaite_ingest')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1c42c96ba246d611ca7037fcc88535e4bbcba522f47de9dbea55008f4eff964"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
