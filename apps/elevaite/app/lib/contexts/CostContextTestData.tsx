


export interface TestCostDataObject {
    id: string;
    account: string;
    project: string;
    modelProvider: string;
    modelId: string;
    inferenceDate: string;
    inferenceHour: number;
    inferenceCount: number;
    tokensIn: number;
    tokensOut?: number;
    latency: number;
    gpu?: number;
    billingType: string;
    cost: number;
}


function getTestDataWithIds(): TestCostDataObject[] {
    return TEST_COST_DATA_BASE.map((item, index) => { return {...item, id: index.toString()}; })
}

const TEST_COST_DATA_BASE: Omit<TestCostDataObject, "id">[] = [
    {
     account: "HR",
     project: "Talent Acquisition",
     modelProvider: "AzureOpenAI",
     modelId: "GPT-4o",
     inferenceDate: "2024-05-01",
     inferenceHour: 1,
     inferenceCount: 24,
     tokensIn: 6000,
     tokensOut: 13920,
     latency: 32134,
     billingType: "Cloud",
     cost: 0.24
    },
    {
     account: "HR",
     project: "Talent Acquisition",
     modelProvider: "AzureOpenAI",
     modelId: "text-embedding-small",
     inferenceDate: "2024-05-01",
     inferenceHour: 1,
     inferenceCount: 1200,
     tokensIn: 2640000,
     latency: 1250,
     billingType: "Cloud",
     cost: 0.34
    },
    {
     account: "Finance",
     project: "Commercial Finance",
     modelProvider: "mistralai",
     modelId: "mistral-7b-instruct-0.2",
     inferenceDate: "2024-05-01",
     inferenceHour: 1,
     inferenceCount: 28,
     tokensIn: 11200,
     tokensOut: 22400,
     latency: 28198,
     gpu: 13.16,
     billingType: "Self Hosted",
     cost: 0.48
    },
    {
     account: "Finance",
     project: "Commercial Finance",
     modelProvider: "snowflake",
     modelId: "snowflake-arctic-embed-1",
     inferenceDate: "2024-05-01",
     inferenceHour: 1,
     inferenceCount: 1800,
     tokensIn: 4500000,
     latency: 1100,
     gpu: 33,
     billingType: "Self Hosted",
     cost: 1.21
    },
    {
     account: "Finance",
     project: "Commercial Finance",
     modelProvider: "facebook",
     modelId: "bart-cnn-large",
     inferenceDate: "2024-05-01",
     inferenceHour: 1,
     inferenceCount: 15,
     tokensIn: 28000,
     tokensOut: 2200,
     latency: 12450,
     gpu: 3.11,
     billingType: "Self Hosted",
     cost: 0.11
    },
    {
     account: "Vendor Management",
     project: "Contract Management",
     modelProvider: "meta-llama",
     modelId: "Meta-Llama-3-8B-Instruct",
     inferenceDate: "2024-05-01",
     inferenceHour: 1,
     inferenceCount: 32,
     tokensIn: 23050,
     tokensOut: 32450,
     latency: 25090,
     gpu: 13.38,
     billingType: "Self Hosted",
     cost: 0.49
    },
    {
     account: "Vendor Management",
     project: "Contract Management",
     modelProvider: "snowflake",
     modelId: "snowflake-arctic-embed-1",
     inferenceDate: "2024-05-01",
     inferenceHour: 1,
     inferenceCount: 1800,
     tokensIn: 4500000,
     latency: 1250,
     gpu: 37.5,
     billingType: "Self Hosted",
     cost: 1.38
    },
    {
     account: "Vendor Management",
     project: "Contract Management",
     modelProvider: "facebook",
     modelId: "bart-cnn-large",
     inferenceDate: "2024-05-01",
     inferenceHour: 1,
     inferenceCount: 30,
     tokensIn: 29000,
     tokensOut: 2500,
     latency: 12450,
     gpu: 6.23,
     billingType: "Self Hosted",
     cost: 0.23
    },
    {
     account: "TAC Support",
     project: "NOC Co-pilot",
     modelProvider: "mistralai",
     modelId: "mistral-7b-instruct-0.2",
     inferenceDate: "2024-05-01",
     inferenceHour: 1,
     inferenceCount: 120,
     tokensIn: 48000,
     tokensOut: 96000,
     latency: 28198,
     gpu: 56.4,
     billingType: "Self Hosted",
     cost: 2.07
    },
    {
     account: "TAC Support",
     project: "NOC Co-pilot",
     modelProvider: "snowflake",
     modelId: "snowflake-arctic-embed-1",
     inferenceDate: "2024-05-01",
     inferenceHour: 1,
     inferenceCount: 1800,
     tokensIn: 4500000,
     latency: 1100,
     gpu: 33,
     billingType: "Self Hosted",
     cost: 1.21
    },
    {
     account: "TAC Support",
     project: "NOC Co-pilot",
     modelProvider: "facebook",
     modelId: "bart-cnn-large",
     inferenceDate: "2024-05-01",
     inferenceHour: 1,
     inferenceCount: 110,
     tokensIn: 28000,
     tokensOut: 2200,
     latency: 12450,
     gpu: 22.83,
     billingType: "Self Hosted",
     cost: 0.84
    },
    {
     account: "Product Support",
     project: "Hardware Firewall",
     modelProvider: "meta-llama",
     modelId: "Meta-Llama-3-8B-Instruct",
     inferenceDate: "2024-05-01",
     inferenceHour: 1,
     inferenceCount: 250,
     tokensIn: 23050,
     tokensOut: 32450,
     latency: 25090,
     gpu: 104.54,
     billingType: "Self Hosted",
     cost: 3.83
    },
    {
     account: "Product Support",
     project: "Hardware Firewall",
     modelProvider: "snowflake",
     modelId: "snowflake-arctic-embed-1",
     inferenceDate: "2024-05-01",
     inferenceHour: 1,
     inferenceCount: 1800,
     tokensIn: 4500000,
     latency: 1250,
     gpu: 37.5,
     billingType: "Self Hosted",
     cost: 1.38
    },
    {
     account: "Product Support",
     project: "Hardware Firewall",
     modelProvider: "facebook",
     modelId: "bart-cnn-large",
     inferenceDate: "2024-05-01",
     inferenceHour: 1,
     inferenceCount: 220,
     tokensIn: 29000,
     tokensOut: 2500,
     latency: 12450,
     gpu: 45.65,
     billingType: "Self Hosted",
     cost: 1.67
    },
    {
     account: "Customer Support",
     project: "Collaboration",
     modelProvider: "meta-llama",
     modelId: "Meta-Llama-3-8B-Instruct",
     inferenceDate: "2024-05-01",
     inferenceHour: 1,
     inferenceCount: 75,
     tokensIn: 23050,
     tokensOut: 32450,
     latency: 25090,
     gpu: 31.36,
     billingType: "Self Hosted",
     cost: 1.15
    },
    {
     account: "Customer Support",
     project: "Collaboration",
     modelProvider: "snowflake",
     modelId: "snowflake-arctic-embed-1",
     inferenceDate: "2024-05-01",
     inferenceHour: 1,
     inferenceCount: 1800,
     tokensIn: 4500000,
     latency: 1250,
     gpu: 37.5,
     billingType: "Self Hosted",
     cost: 1.38
    },
    {
     account: "Customer Support",
     project: "Collaboration",
     modelProvider: "facebook",
     modelId: "bart-cnn-large",
     inferenceDate: "2024-05-01",
     inferenceHour: 1,
     inferenceCount: 60,
     tokensIn: 29000,
     tokensOut: 2500,
     latency: 12450,
     gpu: 12.45,
     billingType: "Self Hosted",
     cost: 0.46
    },
    {
     account: "IT Support",
     project: "Provisioning",
     modelProvider: "meta-llama",
     modelId: "Meta-Llama-3-8B-Instruct",
     inferenceDate: "2024-05-01",
     inferenceHour: 1,
     inferenceCount: 75,
     tokensIn: 23050,
     tokensOut: 32450,
     latency: 25090,
     billingType: "Cloud",
     cost: 0.6
    },
    {
     account: "IT Support",
     project: "Provisioning",
     modelProvider: "cohere",
     modelId: "embed-multilingual-v3.0",
     inferenceDate: "2024-05-01",
     inferenceHour: 1,
     inferenceCount: 2500,
     tokensIn: 6250000,
     latency: 1050,
     billingType: "Cloud",
     cost: 0.81
    },
    {
     account: "IT Support",
     project: "Provisioning",
     modelProvider: "cohere",
     modelId: "summarize",
     inferenceDate: "2024-05-01",
     inferenceHour: 1,
     inferenceCount: 65,
     tokensIn: 29000,
     tokensOut: 2500,
     latency: 10500,
     billingType: "Cloud",
     cost: 0.02
    },
    {
     account: "HR",
     project: "Talent Acquisition",
     modelProvider: "AzureOpenAI",
     modelId: "GPT-4o",
     inferenceDate: "2024-05-01",
     inferenceHour: 2,
     inferenceCount: 30,
     tokensIn: 7500,
     tokensOut: 17400,
     latency: 32134,
     billingType: "Cloud",
     cost: 0.3
    },
    {
     account: "HR",
     project: "Talent Acquisition",
     modelProvider: "AzureOpenAI",
     modelId: "text-embedding-small",
     inferenceDate: "2024-05-01",
     inferenceHour: 2,
     inferenceCount: 1600,
     tokensIn: 3520000,
     latency: 1250,
     billingType: "Cloud",
     cost: 0.46
    },
    {
     account: "Finance",
     project: "Commercial Finance",
     modelProvider: "mistralai",
     modelId: "mistral-7b-instruct-0.2",
     inferenceDate: "2024-05-01",
     inferenceHour: 2,
     inferenceCount: 35,
     tokensIn: 14000,
     tokensOut: 28000,
     latency: 28198,
     gpu: 16.45,
     billingType: "Self Hosted",
     cost: 0.6
    },
    {
     account: "Finance",
     project: "Commercial Finance",
     modelProvider: "snowflake",
     modelId: "snowflake-arctic-embed-1",
     inferenceDate: "2024-05-01",
     inferenceHour: 2,
     inferenceCount: 2500,
     tokensIn: 6250000,
     latency: 1100,
     gpu: 45.83,
     billingType: "Self Hosted",
     cost: 1.68
    },
    {
     account: "Finance",
     project: "Commercial Finance",
     modelProvider: "facebook",
     modelId: "bart-cnn-large",
     inferenceDate: "2024-05-01",
     inferenceHour: 2,
     inferenceCount: 20,
     tokensIn: 28000,
     tokensOut: 2200,
     latency: 12450,
     gpu: 4.15,
     billingType: "Self Hosted",
     cost: 0.15
    },
    {
     account: "Vendor Management",
     project: "Contract Management",
     modelProvider: "meta-llama",
     modelId: "Meta-Llama-3-8B-Instruct",
     inferenceDate: "2024-05-01",
     inferenceHour: 2,
     inferenceCount: 35,
     tokensIn: 23050,
     tokensOut: 32450,
     latency: 25090,
     gpu: 14.64,
     billingType: "Self Hosted",
     cost: 0.54
    },
    {
     account: "Vendor Management",
     project: "Contract Management",
     modelProvider: "snowflake",
     modelId: "snowflake-arctic-embed-1",
     inferenceDate: "2024-05-01",
     inferenceHour: 2,
     inferenceCount: 2000,
     tokensIn: 5000000,
     latency: 1250,
     gpu: 41.67,
     billingType: "Self Hosted",
     cost: 1.53
    },
    {
     account: "Vendor Management",
     project: "Contract Management",
     modelProvider: "facebook",
     modelId: "bart-cnn-large",
     inferenceDate: "2024-05-01",
     inferenceHour: 2,
     inferenceCount: 32,
     tokensIn: 29000,
     tokensOut: 2500,
     latency: 12450,
     gpu: 6.64,
     billingType: "Self Hosted",
     cost: 0.24
    },
    {
     account: "TAC Support",
     project: "NOC Co-pilot",
     modelProvider: "mistralai",
     modelId: "mistral-7b-instruct-0.2",
     inferenceDate: "2024-05-01",
     inferenceHour: 2,
     inferenceCount: 120,
     tokensIn: 48000,
     tokensOut: 96000,
     latency: 28198,
     gpu: 56.4,
     billingType: "Self Hosted",
     cost: 2.07
    },
    {
     account: "TAC Support",
     project: "NOC Co-pilot",
     modelProvider: "snowflake",
     modelId: "snowflake-arctic-embed-1",
     inferenceDate: "2024-05-01",
     inferenceHour: 2,
     inferenceCount: 2200,
     tokensIn: 5500000,
     latency: 1100,
     gpu: 40.33,
     billingType: "Self Hosted",
     cost: 1.48
    },
    {
     account: "TAC Support",
     project: "NOC Co-pilot",
     modelProvider: "facebook",
     modelId: "bart-cnn-large",
     inferenceDate: "2024-05-01",
     inferenceHour: 2,
     inferenceCount: 110,
     tokensIn: 28000,
     tokensOut: 2200,
     latency: 12450,
     gpu: 22.83,
     billingType: "Self Hosted",
     cost: 0.84
    },
    {
     account: "Product Support",
     project: "Hardware Firewall",
     modelProvider: "meta-llama",
     modelId: "Meta-Llama-3-8B-Instruct",
     inferenceDate: "2024-05-01",
     inferenceHour: 2,
     inferenceCount: 250,
     tokensIn: 23050,
     tokensOut: 32450,
     latency: 25090,
     gpu: 104.54,
     billingType: "Self Hosted",
     cost: 3.83
    },
    {
     account: "Product Support",
     project: "Hardware Firewall",
     modelProvider: "snowflake",
     modelId: "snowflake-arctic-embed-1",
     inferenceDate: "2024-05-01",
     inferenceHour: 2,
     inferenceCount: 1800,
     tokensIn: 4500000,
     latency: 1250,
     gpu: 37.5,
     billingType: "Self Hosted",
     cost: 1.38
    },
    {
     account: "Product Support",
     project: "Hardware Firewall",
     modelProvider: "facebook",
     modelId: "bart-cnn-large",
     inferenceDate: "2024-05-01",
     inferenceHour: 2,
     inferenceCount: 220,
     tokensIn: 29000,
     tokensOut: 2500,
     latency: 12450,
     gpu: 45.65,
     billingType: "Self Hosted",
     cost: 1.67
    },
    {
     account: "Customer Support",
     project: "Collaboration",
     modelProvider: "meta-llama",
     modelId: "Meta-Llama-3-8B-Instruct",
     inferenceDate: "2024-05-01",
     inferenceHour: 2,
     inferenceCount: 75,
     tokensIn: 23050,
     tokensOut: 32450,
     latency: 25090,
     gpu: 31.36,
     billingType: "Self Hosted",
     cost: 1.15
    },
    {
     account: "Customer Support",
     project: "Collaboration",
     modelProvider: "snowflake",
     modelId: "snowflake-arctic-embed-1",
     inferenceDate: "2024-05-01",
     inferenceHour: 2,
     inferenceCount: 2200,
     tokensIn: 5500000,
     latency: 1250,
     gpu: 45.83,
     billingType: "Self Hosted",
     cost: 1.68
    },
    {
     account: "Customer Support",
     project: "Collaboration",
     modelProvider: "facebook",
     modelId: "bart-cnn-large",
     inferenceDate: "2024-05-01",
     inferenceHour: 2,
     inferenceCount: 75,
     tokensIn: 29000,
     tokensOut: 2500,
     latency: 12450,
     gpu: 15.56,
     billingType: "Self Hosted",
     cost: 0.57
    },
    {
     account: "IT Support",
     project: "Provisioning",
     modelProvider: "meta-llama",
     modelId: "Meta-Llama-3-8B-Instruct",
     inferenceDate: "2024-05-01",
     inferenceHour: 2,
     inferenceCount: 112,
     tokensIn: 23050,
     tokensOut: 32450,
     latency: 25090,
     billingType: "Cloud",
     cost: 0.6
    },
    {
     account: "IT Support",
     project: "Provisioning",
     modelProvider: "cohere",
     modelId: "embed-multilingual-v3.0",
     inferenceDate: "2024-05-01",
     inferenceHour: 2,
     inferenceCount: 2500,
     tokensIn: 6250000,
     latency: 1050,
     billingType: "Cloud",
     cost: 0.81
    },
    {
     account: "IT Support",
     project: "Provisioning",
     modelProvider: "cohere",
     modelId: "summarize",
     inferenceDate: "2024-05-01",
     inferenceHour: 2,
     inferenceCount: 76,
     tokensIn: 91200,
     tokensOut: 7600,
     latency: 10500,
     billingType: "Cloud",
     cost: 0.07
    },
    {
     account: "HR",
     project: "Talent Acquisition",
     modelProvider: "AzureOpenAI",
     modelId: "GPT-4o",
     inferenceDate: "2024-05-02",
     inferenceHour: 1,
     inferenceCount: 30,
     tokensIn: 7500,
     tokensOut: 17400,
     latency: 32134,
     billingType: "Cloud",
     cost: 0.3
    },
    {
     account: "HR",
     project: "Talent Acquisition",
     modelProvider: "AzureOpenAI",
     modelId: "text-embedding-small",
     inferenceDate: "2024-05-02",
     inferenceHour: 1,
     inferenceCount: 1500,
     tokensIn: 3300000,
     latency: 1250,
     billingType: "Cloud",
     cost: 0.43
    },
    {
     account: "Finance",
     project: "Commercial Finance",
     modelProvider: "mistralai",
     modelId: "mistral-7b-instruct-0.2",
     inferenceDate: "2024-05-02",
     inferenceHour: 1,
     inferenceCount: 50,
     tokensIn: 20000,
     tokensOut: 40000,
     latency: 28198,
     gpu: 23.5,
     billingType: "Self Hosted",
     cost: 0.86
    },
    {
     account: "Finance",
     project: "Commercial Finance",
     modelProvider: "snowflake",
     modelId: "snowflake-arctic-embed-1",
     inferenceDate: "2024-05-02",
     inferenceHour: 1,
     inferenceCount: 2500,
     tokensIn: 6250000,
     latency: 1100,
     gpu: 45.83,
     billingType: "Self Hosted",
     cost: 1.68
    },
    {
     account: "Finance",
     project: "Commercial Finance",
     modelProvider: "facebook",
     modelId: "bart-cnn-large",
     inferenceDate: "2024-05-02",
     inferenceHour: 1,
     inferenceCount: 34,
     tokensIn: 28000,
     tokensOut: 2200,
     latency: 12450,
     gpu: 7.06,
     billingType: "Self Hosted",
     cost: 0.26
    },
    {
     account: "Vendor Management",
     project: "Contract Management",
     modelProvider: "meta-llama",
     modelId: "Meta-Llama-3-8B-Instruct",
     inferenceDate: "2024-05-02",
     inferenceHour: 1,
     inferenceCount: 50,
     tokensIn: 23050,
     tokensOut: 32450,
     latency: 25090,
     gpu: 20.91,
     billingType: "Self Hosted",
     cost: 0.77
    },
    {
     account: "Vendor Management",
     project: "Contract Management",
     modelProvider: "snowflake",
     modelId: "snowflake-arctic-embed-1",
     inferenceDate: "2024-05-02",
     inferenceHour: 1,
     inferenceCount: 2500,
     tokensIn: 6250000,
     latency: 1250,
     gpu: 52.08,
     billingType: "Self Hosted",
     cost: 1.91
    },
    {
     account: "Vendor Management",
     project: "Contract Management",
     modelProvider: "facebook",
     modelId: "bart-cnn-large",
     inferenceDate: "2024-05-02",
     inferenceHour: 1,
     inferenceCount: 32,
     tokensIn: 29000,
     tokensOut: 2500,
     latency: 12450,
     gpu: 6.64,
     billingType: "Self Hosted",
     cost: 0.24
    },
    {
     account: "TAC Support",
     project: "NOC Co-pilot",
     modelProvider: "mistralai",
     modelId: "mistral-7b-instruct-0.2",
     inferenceDate: "2024-05-02",
     inferenceHour: 1,
     inferenceCount: 122,
     tokensIn: 48800,
     tokensOut: 97600,
     latency: 28198,
     gpu: 57.34,
     billingType: "Self Hosted",
     cost: 2.1
    },
    {
     account: "TAC Support",
     project: "NOC Co-pilot",
     modelProvider: "snowflake",
     modelId: "snowflake-arctic-embed-1",
     inferenceDate: "2024-05-02",
     inferenceHour: 1,
     inferenceCount: 1900,
     tokensIn: 4750000,
     latency: 1100,
     gpu: 34.83,
     billingType: "Self Hosted",
     cost: 1.28
    },
    {
     account: "TAC Support",
     project: "NOC Co-pilot",
     modelProvider: "facebook",
     modelId: "bart-cnn-large",
     inferenceDate: "2024-05-02",
     inferenceHour: 1,
     inferenceCount: 220,
     tokensIn: 28000,
     tokensOut: 2200,
     latency: 12450,
     gpu: 45.65,
     billingType: "Self Hosted",
     cost: 1.67
    },
    {
     account: "Product Support",
     project: "Hardware Firewall",
     modelProvider: "meta-llama",
     modelId: "Meta-Llama-3-8B-Instruct",
     inferenceDate: "2024-05-02",
     inferenceHour: 1,
     inferenceCount: 300,
     tokensIn: 23050,
     tokensOut: 32450,
     latency: 25090,
     gpu: 125.45,
     billingType: "Self Hosted",
     cost: 4.6
    },
    {
     account: "Product Support",
     project: "Hardware Firewall",
     modelProvider: "snowflake",
     modelId: "snowflake-arctic-embed-1",
     inferenceDate: "2024-05-02",
     inferenceHour: 1,
     inferenceCount: 3000,
     tokensIn: 7500000,
     latency: 1250,
     gpu: 62.5,
     billingType: "Self Hosted",
     cost: 2.29
    },
    {
     account: "Product Support",
     project: "Hardware Firewall",
     modelProvider: "facebook",
     modelId: "bart-cnn-large",
     inferenceDate: "2024-05-02",
     inferenceHour: 1,
     inferenceCount: 250,
     tokensIn: 29000,
     tokensOut: 2500,
     latency: 12450,
     gpu: 51.88,
     billingType: "Self Hosted",
     cost: 1.9
    },
    {
     account: "Customer Support",
     project: "Collaboration",
     modelProvider: "meta-llama",
     modelId: "Meta-Llama-3-8B-Instruct",
     inferenceDate: "2024-05-02",
     inferenceHour: 1,
     inferenceCount: 89,
     tokensIn: 23050,
     tokensOut: 32450,
     latency: 25090,
     gpu: 37.22,
     billingType: "Self Hosted",
     cost: 1.36
    },
    {
     account: "Customer Support",
     project: "Collaboration",
     modelProvider: "snowflake",
     modelId: "snowflake-arctic-embed-1",
     inferenceDate: "2024-05-02",
     inferenceHour: 1,
     inferenceCount: 2300,
     tokensIn: 5750000,
     latency: 1250,
     gpu: 47.92,
     billingType: "Self Hosted",
     cost: 1.76
    },
    {
     account: "Customer Support",
     project: "Collaboration",
     modelProvider: "facebook",
     modelId: "bart-cnn-large",
     inferenceDate: "2024-05-02",
     inferenceHour: 1,
     inferenceCount: 480,
     tokensIn: 29000,
     tokensOut: 2500,
     latency: 12450,
     gpu: 99.6,
     billingType: "Self Hosted",
     cost: 3.65
    },
    {
     account: "IT Support",
     project: "Provisioning",
     modelProvider: "meta-llama",
     modelId: "Meta-Llama-3-8B-Instruct",
     inferenceDate: "2024-05-02",
     inferenceHour: 1,
     inferenceCount: 90,
     tokensIn: 23050,
     tokensOut: 32450,
     latency: 25090,
     billingType: "Cloud",
     cost: 0.6
    },
    {
     account: "IT Support",
     project: "Provisioning",
     modelProvider: "cohere",
     modelId: "embed-multilingual-v3.0",
     inferenceDate: "2024-05-02",
     inferenceHour: 1,
     inferenceCount: 2750,
     tokensIn: 6875000,
     latency: 1050,
     billingType: "Cloud",
     cost: 0.89
    },
    {
     account: "IT Support",
     project: "Provisioning",
     modelProvider: "cohere",
     modelId: "summarize",
     inferenceDate: "2024-05-02",
     inferenceHour: 1,
     inferenceCount: 102,
     tokensIn: 29000,
     tokensOut: 2500,
     latency: 10500,
     billingType: "Cloud",
     cost: 0.02
    },
    {
     account: "HR",
     project: "Talent Acquisition",
     modelProvider: "AzureOpenAI",
     modelId: "GPT-4o",
     inferenceDate: "2024-05-02",
     inferenceHour: 2,
     inferenceCount: 43,
     tokensIn: 10750,
     tokensOut: 24940,
     latency: 32134,
     billingType: "Cloud",
     cost: 0.43
    },
    {
     account: "HR",
     project: "Talent Acquisition",
     modelProvider: "AzureOpenAI",
     modelId: "text-embedding-small",
     inferenceDate: "2024-05-02",
     inferenceHour: 2,
     inferenceCount: 8500,
     tokensIn: 18700000,
     latency: 1250,
     billingType: "Cloud",
     cost: 2.43
    },
    {
     account: "Finance",
     project: "Commercial Finance",
     modelProvider: "mistralai",
     modelId: "mistral-7b-instruct-0.2",
     inferenceDate: "2024-05-02",
     inferenceHour: 2,
     inferenceCount: 87,
     tokensIn: 34800,
     tokensOut: 69600,
     latency: 28198,
     gpu: 40.89,
     billingType: "Self Hosted",
     cost: 1.5
    },
    {
     account: "Finance",
     project: "Commercial Finance",
     modelProvider: "snowflake",
     modelId: "snowflake-arctic-embed-1",
     inferenceDate: "2024-05-02",
     inferenceHour: 2,
     inferenceCount: 2500,
     tokensIn: 6250000,
     latency: 1100,
     gpu: 45.83,
     billingType: "Self Hosted",
     cost: 1.68
    },
    {
     account: "Finance",
     project: "Commercial Finance",
     modelProvider: "facebook",
     modelId: "bart-cnn-large",
     inferenceDate: "2024-05-02",
     inferenceHour: 2,
     inferenceCount: 20,
     tokensIn: 28000,
     tokensOut: 2200,
     latency: 12450,
     gpu: 4.15,
     billingType: "Self Hosted",
     cost: 0.15
    },
    {
     account: "Vendor Management",
     project: "Contract Management",
     modelProvider: "meta-llama",
     modelId: "Meta-Llama-3-8B-Instruct",
     inferenceDate: "2024-05-02",
     inferenceHour: 2,
     inferenceCount: 35,
     tokensIn: 23050,
     tokensOut: 32450,
     latency: 25090,
     gpu: 14.64,
     billingType: "Self Hosted",
     cost: 0.54
    },
    {
     account: "Vendor Management",
     project: "Contract Management",
     modelProvider: "snowflake",
     modelId: "snowflake-arctic-embed-1",
     inferenceDate: "2024-05-02",
     inferenceHour: 2,
     inferenceCount: 2000,
     tokensIn: 5000000,
     latency: 1250,
     gpu: 41.67,
     billingType: "Self Hosted",
     cost: 1.53
    },
    {
     account: "Vendor Management",
     project: "Contract Management",
     modelProvider: "facebook",
     modelId: "bart-cnn-large",
     inferenceDate: "2024-05-02",
     inferenceHour: 2,
     inferenceCount: 32,
     tokensIn: 29000,
     tokensOut: 2500,
     latency: 12450,
     gpu: 6.64,
     billingType: "Self Hosted",
     cost: 0.24
    },
    {
     account: "TAC Support",
     project: "NOC Co-pilot",
     modelProvider: "mistralai",
     modelId: "mistral-7b-instruct-0.2",
     inferenceDate: "2024-05-02",
     inferenceHour: 2,
     inferenceCount: 120,
     tokensIn: 48000,
     tokensOut: 96000,
     latency: 28198,
     gpu: 56.4,
     billingType: "Self Hosted",
     cost: 2.07
    },
    {
     account: "TAC Support",
     project: "NOC Co-pilot",
     modelProvider: "snowflake",
     modelId: "snowflake-arctic-embed-1",
     inferenceDate: "2024-05-02",
     inferenceHour: 2,
     inferenceCount: 2200,
     tokensIn: 5500000,
     latency: 1100,
     gpu: 40.33,
     billingType: "Self Hosted",
     cost: 1.48
    },
    {
     account: "TAC Support",
     project: "NOC Co-pilot",
     modelProvider: "facebook",
     modelId: "bart-cnn-large",
     inferenceDate: "2024-05-02",
     inferenceHour: 2,
     inferenceCount: 110,
     tokensIn: 28000,
     tokensOut: 2200,
     latency: 12450,
     gpu: 22.83,
     billingType: "Self Hosted",
     cost: 0.84
    },
    {
     account: "Product Support",
     project: "Hardware Firewall",
     modelProvider: "meta-llama",
     modelId: "Meta-Llama-3-8B-Instruct",
     inferenceDate: "2024-05-02",
     inferenceHour: 2,
     inferenceCount: 250,
     tokensIn: 23050,
     tokensOut: 32450,
     latency: 25090,
     gpu: 104.54,
     billingType: "Self Hosted",
     cost: 3.83
    },
    {
     account: "Product Support",
     project: "Hardware Firewall",
     modelProvider: "snowflake",
     modelId: "snowflake-arctic-embed-1",
     inferenceDate: "2024-05-02",
     inferenceHour: 2,
     inferenceCount: 1800,
     tokensIn: 4500000,
     latency: 1250,
     gpu: 37.5,
     billingType: "Self Hosted",
     cost: 1.38
    },
    {
     account: "Product Support",
     project: "Hardware Firewall",
     modelProvider: "facebook",
     modelId: "bart-cnn-large",
     inferenceDate: "2024-05-02",
     inferenceHour: 2,
     inferenceCount: 220,
     tokensIn: 29000,
     tokensOut: 2500,
     latency: 12450,
     gpu: 45.65,
     billingType: "Self Hosted",
     cost: 1.67
    },
    {
     account: "Customer Support",
     project: "Collaboration",
     modelProvider: "meta-llama",
     modelId: "Meta-Llama-3-8B-Instruct",
     inferenceDate: "2024-05-02",
     inferenceHour: 2,
     inferenceCount: 75,
     tokensIn: 23050,
     tokensOut: 32450,
     latency: 25090,
     gpu: 31.36,
     billingType: "Self Hosted",
     cost: 1.15
    },
    {
     account: "Customer Support",
     project: "Collaboration",
     modelProvider: "snowflake",
     modelId: "snowflake-arctic-embed-1",
     inferenceDate: "2024-05-02",
     inferenceHour: 2,
     inferenceCount: 2200,
     tokensIn: 5500000,
     latency: 1250,
     gpu: 45.83,
     billingType: "Self Hosted",
     cost: 1.68
    },
    {
     account: "Customer Support",
     project: "Collaboration",
     modelProvider: "facebook",
     modelId: "bart-cnn-large",
     inferenceDate: "2024-05-02",
     inferenceHour: 2,
     inferenceCount: 75,
     tokensIn: 29000,
     tokensOut: 2500,
     latency: 12450,
     gpu: 15.56,
     billingType: "Self Hosted",
     cost: 0.57
    },
    {
     account: "IT Support",
     project: "Provisioning",
     modelProvider: "meta-llama",
     modelId: "Meta-Llama-3-8B-Instruct",
     inferenceDate: "2024-05-02",
     inferenceHour: 2,
     inferenceCount: 112,
     tokensIn: 23050,
     tokensOut: 32450,
     latency: 25090,
     billingType: "Cloud",
     cost: 0.6
    },
    {
     account: "IT Support",
     project: "Provisioning",
     modelProvider: "cohere",
     modelId: "embed-multilingual-v3.0",
     inferenceDate: "2024-05-02",
     inferenceHour: 2,
     inferenceCount: 2500,
     tokensIn: 6250000,
     latency: 1050,
     billingType: "Cloud",
     cost: 0.81
    },
    {
     account: "IT Support",
     project: "Provisioning",
     modelProvider: "cohere",
     modelId: "summarize",
     inferenceDate: "2024-05-02",
     inferenceHour: 2,
     inferenceCount: 76,
     tokensIn: 91200,
     tokensOut: 7600,
     latency: 10500,
     billingType: "Cloud",
     cost: 0.07
    }
];



export const TEST_COST_DATA: TestCostDataObject[] = getTestDataWithIds();
