"""alligned analytics tables

Revision ID: 67bbbb94d6a4
Revises: 874a732627fe
Create Date: 2025-09-25 15:46:19.682378

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '67bbbb94d6a4'
down_revision: Union[str, None] = '874a732627fe'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('deterministic_workflow_steps', 'execution_pattern',
               existing_type=sa.VARCHAR(),
               nullable=False,
               existing_server_default=sa.text("'sequential'::character varying"))
    op.alter_column('deterministic_workflow_steps', 'rollback_attempted',
               existing_type=sa.BOOLEAN(),
               nullable=False,
               existing_server_default=sa.text('false'))
    op.drop_index('ix_deterministic_workflow_steps_execution_id', table_name='deterministic_workflow_steps')
    op.drop_index('ix_deterministic_workflow_steps_start_time', table_name='deterministic_workflow_steps')
    op.drop_index('ix_deterministic_workflow_steps_status', table_name='deterministic_workflow_steps')
    op.drop_index('ix_deterministic_workflow_steps_step_type', table_name='deterministic_workflow_steps')
    op.add_column('workflow_execution_steps', sa.Column('step_index', sa.Integer(), nullable=False))
    op.add_column('workflow_execution_steps', sa.Column('agent_name', sa.String(), nullable=True))
    op.add_column('workflow_execution_steps', sa.Column('tool_name', sa.String(), nullable=True))
    op.add_column('workflow_execution_steps', sa.Column('started_at', sa.DateTime(), nullable=True))
    op.add_column('workflow_execution_steps', sa.Column('completed_at', sa.DateTime(), nullable=True))
    op.add_column('workflow_execution_steps', sa.Column('error', sa.Text(), nullable=True))
    op.alter_column('workflow_execution_steps', 'step_type',
               existing_type=sa.VARCHAR(),
               nullable=False)
    op.drop_constraint('uix_execution_step_id', 'workflow_execution_steps', type_='unique')
    op.create_unique_constraint('uix_execution_step', 'workflow_execution_steps', ['execution_id', 'step_id'])
    op.drop_constraint('workflow_execution_steps_agent_id_fkey', 'workflow_execution_steps', type_='foreignkey')
    op.drop_column('workflow_execution_steps', 'start_time')
    op.drop_column('workflow_execution_steps', 'error_message')
    op.drop_column('workflow_execution_steps', 'step_order')
    op.drop_column('workflow_execution_steps', 'end_time')
    op.drop_column('workflow_execution_steps', 'retry_count')
    op.drop_column('workflow_execution_steps', 'step_name')
    op.add_column('workflow_executions', sa.Column('execution_type', sa.String(), nullable=False))
    op.add_column('workflow_executions', sa.Column('progress', sa.Float(), nullable=True))
    op.add_column('workflow_executions', sa.Column('current_step', sa.String(), nullable=True))
    op.add_column('workflow_executions', sa.Column('query', sa.Text(), nullable=True))
    op.add_column('workflow_executions', sa.Column('result', postgresql.JSONB(astext_type=sa.Text()), nullable=True))
    op.add_column('workflow_executions', sa.Column('error', sa.Text(), nullable=True))
    op.add_column('workflow_executions', sa.Column('tools_called', postgresql.JSONB(astext_type=sa.Text()), nullable=True))
    op.add_column('workflow_executions', sa.Column('created_at', sa.DateTime(), nullable=False))
    op.add_column('workflow_executions', sa.Column('started_at', sa.DateTime(), nullable=True))
    op.add_column('workflow_executions', sa.Column('completed_at', sa.DateTime(), nullable=True))
    op.add_column('workflow_executions', sa.Column('estimated_completion', sa.DateTime(), nullable=True))
    op.alter_column('workflow_executions', 'current_step_index',
               existing_type=sa.INTEGER(),
               nullable=False,
               existing_server_default=sa.text('0'))
    op.alter_column('workflow_executions', 'total_steps',
               existing_type=sa.INTEGER(),
               nullable=False,
               existing_server_default=sa.text('0'))
    op.drop_column('workflow_executions', 'start_time')
    op.drop_column('workflow_executions', 'error_type')
    op.drop_column('workflow_executions', 'error_message')
    op.drop_column('workflow_executions', 'max_retries')
    op.drop_column('workflow_executions', 'output_data')
    op.drop_column('workflow_executions', 'end_time')
    op.drop_column('workflow_executions', 'duration_ms')
    op.drop_column('workflow_executions', 'tags')
    op.drop_column('workflow_executions', 'retry_count')
    op.drop_column('workflow_executions', 'priority')
    op.drop_column('workflow_executions', 'error_details')
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('workflow_executions', sa.Column('error_details', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True))
    op.add_column('workflow_executions', sa.Column('priority', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=True))
    op.add_column('workflow_executions', sa.Column('retry_count', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=True))
    op.add_column('workflow_executions', sa.Column('tags', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True))
    op.add_column('workflow_executions', sa.Column('duration_ms', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('workflow_executions', sa.Column('end_time', postgresql.TIMESTAMP(), autoincrement=False, nullable=True))
    op.add_column('workflow_executions', sa.Column('output_data', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True))
    op.add_column('workflow_executions', sa.Column('max_retries', sa.INTEGER(), server_default=sa.text('3'), autoincrement=False, nullable=True))
    op.add_column('workflow_executions', sa.Column('error_message', sa.TEXT(), autoincrement=False, nullable=True))
    op.add_column('workflow_executions', sa.Column('error_type', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.add_column('workflow_executions', sa.Column('start_time', postgresql.TIMESTAMP(), autoincrement=False, nullable=True))
    op.alter_column('workflow_executions', 'total_steps',
               existing_type=sa.INTEGER(),
               nullable=True,
               existing_server_default=sa.text('0'))
    op.alter_column('workflow_executions', 'current_step_index',
               existing_type=sa.INTEGER(),
               nullable=True,
               existing_server_default=sa.text('0'))
    op.drop_column('workflow_executions', 'estimated_completion')
    op.drop_column('workflow_executions', 'completed_at')
    op.drop_column('workflow_executions', 'started_at')
    op.drop_column('workflow_executions', 'created_at')
    op.drop_column('workflow_executions', 'tools_called')
    op.drop_column('workflow_executions', 'error')
    op.drop_column('workflow_executions', 'result')
    op.drop_column('workflow_executions', 'query')
    op.drop_column('workflow_executions', 'current_step')
    op.drop_column('workflow_executions', 'progress')
    op.drop_column('workflow_executions', 'execution_type')
    op.add_column('workflow_execution_steps', sa.Column('step_name', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.add_column('workflow_execution_steps', sa.Column('retry_count', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=True))
    op.add_column('workflow_execution_steps', sa.Column('end_time', postgresql.TIMESTAMP(), autoincrement=False, nullable=True))
    op.add_column('workflow_execution_steps', sa.Column('step_order', sa.INTEGER(), autoincrement=False, nullable=False))
    op.add_column('workflow_execution_steps', sa.Column('error_message', sa.TEXT(), autoincrement=False, nullable=True))
    op.add_column('workflow_execution_steps', sa.Column('start_time', postgresql.TIMESTAMP(), autoincrement=False, nullable=True))
    op.create_foreign_key('workflow_execution_steps_agent_id_fkey', 'workflow_execution_steps', 'agents', ['agent_id'], ['agent_id'])
    op.drop_constraint('uix_execution_step', 'workflow_execution_steps', type_='unique')
    op.create_unique_constraint('uix_execution_step_id', 'workflow_execution_steps', ['execution_id', 'step_id'])
    op.alter_column('workflow_execution_steps', 'step_type',
               existing_type=sa.VARCHAR(),
               nullable=True)
    op.drop_column('workflow_execution_steps', 'error')
    op.drop_column('workflow_execution_steps', 'completed_at')
    op.drop_column('workflow_execution_steps', 'started_at')
    op.drop_column('workflow_execution_steps', 'tool_name')
    op.drop_column('workflow_execution_steps', 'agent_name')
    op.drop_column('workflow_execution_steps', 'step_index')
    op.create_index('ix_deterministic_workflow_steps_step_type', 'deterministic_workflow_steps', ['step_type'], unique=False)
    op.create_index('ix_deterministic_workflow_steps_status', 'deterministic_workflow_steps', ['status'], unique=False)
    op.create_index('ix_deterministic_workflow_steps_start_time', 'deterministic_workflow_steps', ['start_time'], unique=False)
    op.create_index('ix_deterministic_workflow_steps_execution_id', 'deterministic_workflow_steps', ['execution_id'], unique=False)
    op.alter_column('deterministic_workflow_steps', 'rollback_attempted',
               existing_type=sa.BOOLEAN(),
               nullable=True,
               existing_server_default=sa.text('false'))
    op.alter_column('deterministic_workflow_steps', 'execution_pattern',
               existing_type=sa.VARCHAR(),
               nullable=True,
               existing_server_default=sa.text("'sequential'::character varying"))
    # ### end Alembic commands ###
